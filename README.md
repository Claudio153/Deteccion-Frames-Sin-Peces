# üß† Proyecto de Clasificaci√≥n de Frames de Salmones

Este repositorio contiene el desarrollo de un modelo de clasificaci√≥n binaria basado en **MobileNetV3** para distinguir entre frames **con peces** y **vac√≠os** dentro de secuencias de video. El proyecto incluye el preprocesamiento de datos, el entrenamiento con **validaci√≥n cruzada (K-Fold)** y la evaluaci√≥n final en un conjunto de prueba independiente.

---

## üìÇ Estructura del Repositorio

```
salmon-detector/
‚îÇ
|
‚îú‚îÄ‚îÄ Preprocesamiento.ipynb   ‚Üê Data augmentation (offline) para clase "vacio"
‚îú‚îÄ‚îÄ Entrenamiento.ipynb      ‚Üê Entrenamiento + validaci√≥n cruzada + m√©tricas finales
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml                 ‚Üê Dependencias gestionadas por UV
‚îú‚îÄ‚îÄ requirements.txt               ‚Üê Alternativa manual (opcional)
‚îú‚îÄ‚îÄ README.md                      ‚Üê Este archivo
‚îî‚îÄ‚îÄ 
```

> üß© **Importante:** El dataset es confidencial y no se incluye en este repositorio. Debe cargarse manualmente desde una fuente privada (por ejemplo, Google Drive).

---

## ‚öôÔ∏è Instalaci√≥n y Ejecuci√≥n

> **Requisitos previos:** Tener instalado [Python 3.12](https://www.python.org/downloads/) y [UV](https://docs.astral.sh/uv/).

### 1Ô∏è‚É£ Clonar el repositorio

```bash
git clone [https://github.com/<tu_usuario>/salmon-detector.git](https://github.com/Claudio153/Deteccion-Frames-Sin-Peces.git)
cd Deteccion-Frames-Sin-Peces
```

### 2Ô∏è‚É£ Crear el entorno y resolver dependencias

```bash
uv sync
```

Esto:

* Crea autom√°ticamente el entorno virtual `.venv`
* Instala todas las dependencias especificadas en `pyproject.toml`

### 3Ô∏è‚É£ Ejecutar el entorno de trabajo (JupyterLab)

```bash
uv run jupyter lab
```

Esto abrir√° **JupyterLab** en tu navegador, desde donde podr√°s ejecutar los notebooks paso a paso.

---

## üß† Flujo de Ejecuci√≥n del Proyecto

1. **Preprocesamiento (Preprocesamiento.ipynb):**

   * Aumenta la cantidad de im√°genes de la clase `vacio` mediante t√©cnicas de data augmentation offline.
   * Guarda los nuevos frames en el dataset local.

2. **Entrenamiento (Entrenamiento.ipynb):**

   * Entrena el modelo usando validaci√≥n cruzada (5 folds estratificados).
   * Eval√∫a m√©tricas de rendimiento: *Precision, Recall, F1-score y Accuracy*.
   * Guarda autom√°ticamente el mejor modelo (`mobilenetv3_binaria_best.pt`).

3. **Evaluaci√≥n final:**

   * Usa un conjunto de prueba externo (`datasets_test/`) para medir el desempe√±o final del modelo.
   * Genera la matriz de confusi√≥n y el reporte de clasificaci√≥n.



## üß© Notas adicionales

* Se usa **MobileNetV3 Small** preentrenada en *ImageNet* y ajustada a 2 clases: `con_pez` y `vacio`.
* La funci√≥n de p√©rdida aplica un **peso mayor a la clase `con_pez`**, priorizando evitar falsos negativos (frames con peces clasificados como vac√≠os).
* El entrenamiento emplea **Early Stopping** y **ReduceLROnPlateau** para optimizar la convergencia.

---

## üßæ Comandos √ötiles

| Acci√≥n                       | Comando              |
| ---------------------------- | -------------------- |
| Crear entorno y dependencias | `uv sync`            |
| Iniciar JupyterLab           | `uv run jupyter lab` |
| Limpiar entorno              | `uv clean`           |

---

## üßë‚Äçüíª Autor

**Claudio D√≠az**
Proyecto acad√©mico ‚Äì Universidad San Sebasti√°n, 2025.
