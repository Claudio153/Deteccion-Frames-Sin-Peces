# ğŸŸ DetecciÃ³n de Frames VacÃ­os en Secuencias de Video

Este proyecto implementa un modelo de **clasificaciÃ³n binaria** basado en **MobileNetV3 preentrenada en ImageNet**, cuyo objetivo es **identificar y eliminar frames vacÃ­os** (sin peces) provenientes de secuencias de video de inspecciÃ³n.
El propÃ³sito es optimizar el procesamiento de datos, eliminando los frames que no aportan informaciÃ³n Ãºtil.

---

## ğŸ¯ Objetivo del proyecto

El objetivo principal es desarrollar un modelo de visiÃ³n por computador que:

* Clasifique los frames en dos categorÃ­as: **con_pez** y **vacio**.
* Evite a toda costa eliminar frames con peces.
* Utilice **transfer learning** con la red **MobileNetV3-Small**.

---

## âš™ï¸ Etapas del proyecto

### 1ï¸âƒ£ Preprocesamiento (`Preprocesamiento.ipynb`)

En esta etapa se:

* Cargan los datasets originales desde:

  ```
  datasets/con_pez/
  datasets/vacio/
  ```
* Se aplica **redimensionamiento** de imÃ¡genes a **224Ã—224 pÃ­xeles**.
* Se realiza **data augmentation offline** sobre los frames vacÃ­os (rotaciÃ³n leve, espejado, cambios de contraste, brillo y blur suave).
* Se balancea el dataset final seleccionando aleatoriamente un nÃºmero similar de imÃ¡genes con peces.
* Finalmente, se divide el dataset en:

  ```
  datasets_final/
  â”œâ”€â”€ train/
  â””â”€â”€ val/
  ```

  con una proporciÃ³n **80% entrenamiento / 20% validaciÃ³n**.

---

### 2ï¸âƒ£ Entrenamiento (`Entrenamiento.ipynb`)

Durante el entrenamiento:

* Se aplica **data augmentation al vuelo** con `torchvision.transforms`:

  * Recortes aleatorios (`RandomResizedCrop`)
  * Rotaciones leves (`RandomRotation`)
  * Flips horizontales
  * Cambios de color y contraste (`ColorJitter`)
  * Blur gaussiano
* Las imÃ¡genes se **normalizan** siguiendo las estadÃ­sticas de **ImageNet**.
* Se entrena una **MobileNetV3-Small** con fine-tuning:

  ```python
  model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.IMAGENET1K_V1)
  model.classifier[3] = nn.Linear(1024, 2)  # ['con_pez', 'vacio']
  ```
* Se utiliza **CrossEntropyLoss** con pesos ajustados para penalizar mÃ¡s los errores al clasificar frames con peces:

  ```python
  criterion = nn.CrossEntropyLoss(weight=torch.tensor([2.0, 1.0]).to(DEVICE))
  ```
* OptimizaciÃ³n con **Adam** y **scheduler**:

  ```python
  optimizer = optim.Adam(model.parameters(), lr=3e-4)
  scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)
  ```
* Se implementa **early stopping** automÃ¡tico basado en `val_acc`.

El modelo final se guarda como:

```
mobilenetv3_binaria_best.pt
```

---

## ğŸ“Š EvaluaciÃ³n

El modelo se evalÃºa sobre el conjunto de validaciÃ³n usando mÃ©tricas de clasificaciÃ³n:

* **Matriz de confusiÃ³n**
* **PrecisiÃ³n (Precision)**
* **Sensibilidad (Recall)**
* **F1-score**
* **Accuracy global**

Ejemplo de resultados:

```
=== MATRIZ DE CONFUSIÃ“N ===
[[231   2]
 [  0 150]]

=== MÃ‰TRICAS POR CLASE ===
con_pez    â†’ Precision: 1.000 | Recall: 0.991 | F1-score: 0.996
vacio      â†’ Precision: 0.987 | Recall: 1.000 | F1-score: 0.993

=== ACCURACY GLOBAL ===
0.995
```

**InterpretaciÃ³n:**

* Alta precisiÃ³n en â€œvacioâ€ â†’ elimina muy pocos frames con peces.
* Alto recall en â€œvacioâ€ â†’ detecta correctamente la mayorÃ­a de los frames vacÃ­os.
* Excelente equilibrio general (F1 â‰ˆ 0.99).

---

## ğŸ§± Estructura del proyecto

```
deteccion_frames_vacios/
â”‚
â”œâ”€â”€ Preprocesamiento.ipynb
â”œâ”€â”€Entrenamiento.ipynb
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ con_pez/
â”‚   â”‚    â”œâ”€â”€ 1_pez/
â”‚   â”‚    â”œâ”€â”€ 2_peces/
â”‚   â”‚    â””â”€â”€ 3_peces/
â”‚   â”‚ 
â”‚   â””â”€â”€ vacio/
â”‚
â”œâ”€â”€ mobilenetv3_binaria_best.pt
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸ’» InstalaciÃ³n y ejecuciÃ³n

### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/<tu_usuario>/deteccion_frames_vacios.git
cd deteccion_frames_vacios
```

### 2ï¸âƒ£ Crear un entorno virtual (opcional)

```bash
python -m venv .venv
source .venv/bin/activate  # Linux
.venv\Scripts\activate     # Windows
```

### 3ï¸âƒ£ Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Ejecutar notebooks

```bash
jupyter notebook
```

---

## ğŸ“¦ Dependencias principales (`requirements.txt`)

Estas librerÃ­as se extraen directamente de los notebooks:

```
torch==2.4.0
torchvision==0.19.0
numpy==2.1.1
pillow==10.4.0
matplotlib==3.9.2
scikit-learn==1.5.2
tqdm==4.66.5
```

---

## ğŸ§  Consideraciones finales

* El modelo prioriza **no eliminar frames con peces**.
* Se ajustÃ³ la funciÃ³n de pÃ©rdida para penalizar mÃ¡s los falsos vacÃ­os.
* El entrenamiento y validaciÃ³n se realizaron con imÃ¡genes **balanceadas y aumentadas**.
* Se utilizÃ³ **precisiÃ³n mixta (AMP)** para acelerar el entrenamiento en GPU.

---

## ğŸ“š Licencia

Este proyecto se distribuye bajo licencia **MIT**, permitiendo su libre uso y modificaciÃ³n con fines acadÃ©micos o de investigaciÃ³n.
