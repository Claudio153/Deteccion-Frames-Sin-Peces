{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cc1002c-b611-4166-beba-b02aadb9f2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas: ['con_pez', 'vacio']\n",
      "Diccionario de clase:  {'con_pez': 0, 'vacio': 1}\n",
      "Conteos por grupo (train | val):\n",
      "  vacio   :  600 |  150\n",
      "  1_pez   :  624 |  157\n",
      "  2_peces :  209 |   53\n",
      "  3_peces :   91 |   23\n",
      "TOTAL -> train: 1524 | val: 383\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "# === CONFIG ===\n",
    "ROOT = \"datasets\"         # contiene 'vacio/' y 'con_pez/' (con subcarpetas 1/2/3)\n",
    "TRAIN_RATIO = 0.8\n",
    "BATCH_SIZE  = 32\n",
    "SEED        = 2908\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "# Transformaciones (idénticas a las de ImageNet)\n",
    "train_tf = transforms.Compose([\n",
    "    # Pequeña variacion de encuadre/zoom\n",
    "    transforms.RandomResizedCrop(\n",
    "        size=224, scale=(0.90, 1.00), ratio=(0.95, 1.05), interpolation=InterpolationMode.BICUBIC\n",
    "    ),\n",
    "    #Simetria horizontal (no afecta para vacio)\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # Rotacion leve, aplicada solo a veces\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomRotation(degrees=8, interpolation=InterpolationMode.BICUBIC)\n",
    "    ], p=0.4),\n",
    "    # Variaciones de luz/contraste/saturacion/tono, aplicada solo a veces\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.10, hue=0.02)\n",
    "    ], p=0.5),\n",
    "    # Simula pequeño motion blur\n",
    "    transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.8))\n",
    "    ], p=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Cargar datasets y aplicar transformaciones (ImageFolder detecta las subcarpetas de primer nivel de ROOT y las convierte en una clase)\n",
    "ds_train_view = datasets.ImageFolder(ROOT, transform=train_tf)\n",
    "ds_val_view   = datasets.ImageFolder(ROOT, transform=val_tf)\n",
    "\n",
    "print(\"Clases detectadas:\", ds_train_view.classes) \n",
    "class_to_idx = ds_train_view.class_to_idx   # Diccionario de clases generado automaticamente por ImageFolder\n",
    "idx_con = class_to_idx[\"con_pez\"]\n",
    "idx_vac = class_to_idx[\"vacio\"]\n",
    "print(\"Diccionario de clase: \", class_to_idx)\n",
    "\n",
    "samples = ds_train_view.samples # Lista de tuplas de las imagenes con sus respectivas etiquetas numericas (0, 1)\n",
    "\n",
    "# --- Recolectar índices ---\n",
    "def indices_con_pez_de(subcarpeta: str):\n",
    "    idxs = []\n",
    "    for i, (p, y) in enumerate(samples):\n",
    "        if y == idx_con and subcarpeta in Path(p).parts:\n",
    "            idxs.append(i)       \n",
    "    return idxs\n",
    "\n",
    "idx_vacio = [i for i, (_, y) in enumerate(samples) if y == idx_vac]\n",
    "idx_con_1 = indices_con_pez_de(\"1_pez\")\n",
    "idx_con_2 = indices_con_pez_de(\"2_peces\")\n",
    "idx_con_3 = indices_con_pez_de(\"3_peces\")\n",
    "\n",
    "# Toma una lista con indices y divide esta lista para train y val (0.8 para train y 0.2 para val)\n",
    "def split_indices(idxs, ratio=TRAIN_RATIO):\n",
    "    idxx = idxs[:]\n",
    "    random.shuffle(idxx)\n",
    "    k = int(len(idxx) * ratio)\n",
    "    return idxx[:k], idxx[k:]\n",
    "    \n",
    "tr_vac, va_vac = split_indices(idx_vacio)\n",
    "tr_1,   va_1   = split_indices(idx_con_1)\n",
    "tr_2,   va_2   = split_indices(idx_con_2)\n",
    "tr_3,   va_3   = split_indices(idx_con_3)\n",
    "\n",
    "train_indices = tr_vac + tr_1 + tr_2 + tr_3\n",
    "val_indices   = va_vac + va_1 + va_2 + va_3\n",
    "\n",
    "train_ds = Subset(ds_train_view, train_indices)  # augment al vuelo (train_tf)\n",
    "val_ds   = Subset(ds_val_view,   val_indices)    # sin augment (val_tf)\n",
    "\n",
    "\n",
    "# --- Reporte rápido ---\n",
    "print(\"Conteos por grupo (train | val):\")\n",
    "print(f\"  vacio   : {len(tr_vac):4d} | {len(va_vac):4d}\")\n",
    "print(f\"  1_pez   : {len(tr_1):4d} | {len(va_1):4d}\")\n",
    "print(f\"  2_peces : {len(tr_2):4d} | {len(va_2):4d}\")\n",
    "print(f\"  3_peces : {len(tr_3):4d} | {len(va_3):4d}\")\n",
    "print(f\"TOTAL -> train: {len(train_ds)} | val: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd8d96e2-5e89-484b-b843-9be450553431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.1933 acc=0.885 | val_loss=1.4591 acc=0.473 | lr=3.00e-04\n",
      "Epoch 02 | train_loss=0.0654 acc=0.969 | val_loss=0.7444 acc=0.768 | lr=3.00e-04\n",
      "Epoch 03 | train_loss=0.0534 acc=0.973 | val_loss=0.4690 acc=0.854 | lr=3.00e-04\n",
      "Epoch 04 | train_loss=0.0348 acc=0.989 | val_loss=2.3311 acc=0.496 | lr=3.00e-04\n",
      "Epoch 05 | train_loss=0.0346 acc=0.985 | val_loss=1.2761 acc=0.668 | lr=3.00e-04\n",
      "Epoch 06 | train_loss=0.0213 acc=0.993 | val_loss=0.6106 acc=0.825 | lr=1.50e-04\n",
      "Epoch 07 | train_loss=0.0169 acc=0.993 | val_loss=0.2162 acc=0.945 | lr=1.50e-04\n",
      "Epoch 08 | train_loss=0.0143 acc=0.995 | val_loss=0.0343 acc=0.982 | lr=1.50e-04\n",
      "Epoch 09 | train_loss=0.0174 acc=0.992 | val_loss=0.0463 acc=0.982 | lr=1.50e-04\n",
      "Epoch 10 | train_loss=0.0155 acc=0.993 | val_loss=0.0341 acc=0.984 | lr=1.50e-04\n",
      "Epoch 11 | train_loss=0.0110 acc=0.994 | val_loss=0.0487 acc=0.979 | lr=1.50e-04\n",
      "Epoch 12 | train_loss=0.0155 acc=0.995 | val_loss=0.1134 acc=0.953 | lr=1.50e-04\n",
      "Epoch 13 | train_loss=0.0122 acc=0.995 | val_loss=0.1598 acc=0.937 | lr=7.50e-05\n",
      "Epoch 14 | train_loss=0.0046 acc=1.000 | val_loss=0.1354 acc=0.945 | lr=7.50e-05\n",
      "Epoch 15 | train_loss=0.0127 acc=0.995 | val_loss=0.0645 acc=0.979 | lr=7.50e-05\n",
      "Early stopping: sin mejora en val_acc por 5 épocas.\n",
      "\n",
      "Mejor val_acc = 0.984. Pesos guardados en: mobilenetv3_binaria_best.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim, amp\n",
    "from torchvision import models\n",
    "\n",
    "# ===== Configuración de entrenamiento =====\n",
    "EPOCHS = 15\n",
    "LR     = 3e-4\n",
    "PATIENCE = 5  # early stopping por falta de mejora en val_acc\n",
    "\n",
    "# Asegura reproducibilidad básica \n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      num_workers=2, pin_memory=(DEVICE==\"cuda\"))\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                      num_workers=2, pin_memory=(DEVICE==\"cuda\"))\n",
    "\n",
    "# ===== Modelo: MobileNetV3 preentrenada en ImageNet → 2 clases =====\n",
    "model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.IMAGENET1K_V1)\n",
    "model.classifier[3] = nn.Linear(1024, 2)  # ['con_pez','vacio']\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([2.0, 1.0]).to(DEVICE))\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# (Opcional) Scheduler suave que reduce LR si no mejora la val_loss\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5,\n",
    "                                                 patience=2)\n",
    "\n",
    "# ===== Funciones auxiliares =====\n",
    "def run_epoch(dataloader, train: bool):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "\n",
    "    # AMP opcional para GPU: acelera y ahorra VRAM (solo si DEVICE == 'cuda')\n",
    "    scaler = amp.GradScaler(device=\"cuda\", enabled=(DEVICE == \"cuda\"))\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with amp.autocast(device_type=\"cuda\", enabled=(DEVICE == \"cuda\")):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "\n",
    "            if train:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "        loss_sum += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total   += x.size(0)\n",
    "\n",
    "    avg_loss = loss_sum / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "# ===== Loop de entrenamiento con early stopping =====\n",
    "best_acc = 0.0\n",
    "best_state = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = run_epoch(train_dl, train=True)\n",
    "    val_loss,   val_acc   = run_epoch(val_dl,   train=False)\n",
    "\n",
    "    # Scheduler por val_loss\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"train_loss={train_loss:.4f} acc={train_acc:.3f} | \"\n",
    "          f\"val_loss={val_loss:.4f} acc={val_acc:.3f} | \"\n",
    "          f\"lr={optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    # Guardar mejor por val_acc\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"Early stopping: sin mejora en val_acc por {PATIENCE} épocas.\")\n",
    "            break\n",
    "\n",
    "# ===== Guardado del mejor modelo =====\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "save_path = \"mobilenetv3_binaria_best.pt\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"\\nMejor val_acc = {best_acc:.3f}. Pesos guardados en: {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f1e756e-8948-4f54-aef1-9924caa98f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MATRIZ DE CONFUSIÓN ===\n",
      "[[232   1]\n",
      " [  5 145]]\n",
      "\n",
      "=== MÉTRICAS POR CLASE ===\n",
      "con_pez    → Precision: 0.979 | Recall: 0.996 | F1-score: 0.987\n",
      "vacio      → Precision: 0.993 | Recall: 0.967 | F1-score: 0.980\n",
      "\n",
      "=== ACCURACY GLOBAL ===\n",
      "0.984\n",
      "\n",
      "Interpretación:\n",
      " - Alta precisión en 'vacio' → el modelo elimina pocos frames con peces.\n",
      " - Alto recall en 'vacio' → el modelo elimina la mayoría de los frames realmente vacíos.\n",
      " - Accuracy mide el porcentaje total de aciertos sobre todo el conjunto de validación.\n"
     ]
    }
   ],
   "source": [
    "# ===== BLOQUE DE EVALUACIÓN FINAL =====\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "# --- Modo evaluación ---\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "# --- Recolectar todas las predicciones sobre el conjunto de validación ---\n",
    "with torch.no_grad():\n",
    "    for x, y in val_dl:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1)\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# --- Matriz de confusión ---\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\n=== MATRIZ DE CONFUSIÓN ===\")\n",
    "print(cm)\n",
    "\n",
    "# --- Métricas por clase ---\n",
    "precision = precision_score(y_true, y_pred, average=None)\n",
    "recall    = recall_score(y_true, y_pred, average=None)\n",
    "f1        = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "# --- Accuracy global ---\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# --- Nombres de las clases ---\n",
    "try:\n",
    "    clases = train_dl.dataset.dataset.classes\n",
    "except:\n",
    "    clases = [\"con_pez\", \"vacio\"]\n",
    "\n",
    "# --- Reporte detallado por clase ---\n",
    "print(\"\\n=== MÉTRICAS POR CLASE ===\")\n",
    "for i, nombre in enumerate(clases):\n",
    "    print(f\"{nombre:10s} → Precision: {precision[i]:.3f} | Recall: {recall[i]:.3f} | F1-score: {f1[i]:.3f}\")\n",
    "\n",
    "print(f\"\\n=== ACCURACY GLOBAL ===\\n{accuracy:.3f}\")\n",
    "\n",
    "# --- Interpretación breve ---\n",
    "print(\"\\nInterpretación:\")\n",
    "print(\" - Alta precisión en 'vacio' → el modelo elimina pocos frames con peces.\")\n",
    "print(\" - Alto recall en 'vacio' → el modelo elimina la mayoría de los frames realmente vacíos.\")\n",
    "print(\" - Accuracy mide el porcentaje total de aciertos sobre todo el conjunto de validación.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab41a3-442c-45f7-aa3c-5d971b67bc73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
